# Cumulative for the  Parsing Output
<details><summary>Learning Objectives</summary>

# Learning Objectives for the Parsing Output topic.

### Learning Objectives

After completing this module, associates should be able to:
- Organize output information from LLMs
- Use the two methods for output parsers

</details>
<details><summary>Description</summary>

# Description of the Parsing Output topic.

### Parsing Output
Language models generate textual outputs, but there are instances where obtaining more organized information is preferable to raw text. This is where the role of output parsers becomes crucial.

Output parsers, serving as specialized classes, play a pivotal role in organizing language model responses. Two fundamental methods must be incorporated into an output parser:

1. "Retrieve formatting instructions": This method should yield a string comprising guidelines on how to format the output generated by a language model.

2. "Parsing": This method involves taking a string (assumed to be the language model's response) and structuring it into a specific format.

Additionally, there is an optional method:

3. "Parse with prompt": This method accepts both a string (assumed to be the language model's response) and a prompt (presumed to be the input that led to the given response). Its purpose is to structure the output into a specific format. The provision of the prompt becomes significant in scenarios where the Output Parser needs to reattempt or rectify the output and requires prompt-related information to do so.
</details>
<details><summary>Implementation</summary> 

# Implementation for the Parsing Output topic

first here is the setup:
### Parsing Output

```python
from langchain.llms import OpenAI
from langchain.output_parsers import PydanticOutputParser
from langchain.prompts import PromptTemplate
from langchain.pydantic_v1 import BaseModel, Field, validator

model = OpenAI(model_name="text-davinci-003", temperature=0.0)


# Define your desired data structure.
class Joke(BaseModel):
    setup: str = Field(description="question to set up a joke")
    punchline: str = Field(description="answer to resolve the joke")

    # You can add custom validation logic easily with Pydantic.
    @validator("setup")
    def question_ends_with_question_mark(cls, field):
        if field[-1] != "?":
            raise ValueError("Badly formed question!")
        return field


# Set up a parser + inject instructions into the prompt template.
parser = PydanticOutputParser(pydantic_object=Joke)

prompt = PromptTemplate(
    template="Answer the user query.\n{format_instructions}\n{query}\n",
    input_variables=["query"],
    partial_variables={"format_instructions": parser.get_format_instructions()},
)

# And a query intended to prompt a language model to populate the data structure.
prompt_and_model = prompt | model
output = prompt_and_model.invoke({"query": "Tell me a joke."})
parser.invoke(output)
```
Then add it to our Runnable sequence:
```python
chain = prompt | model | parser
chain.invoke({"query": "Tell me a joke."})

Joke(setup='Why did the scarecrow win an award??', punchline='Because he was outstanding in his field!')
```

</details>
